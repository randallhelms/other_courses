**Big Data Querying with Hive**

What is Hive?

	* Efficient data warehouse infrastructure that allows SQL users to explore Hadoop platform
	* Works on top of Hadoop framework to manage and query unstructured data
	* Designed for analysis of huge volumes of data
	* HQL: query language similar to SQL
	
	Hive provides:
	
	* Pluggable MapReduce scripts in language of choice
	* Rich and user-defined data types
	* User Defined Functions (UDFs)
	* Interoperability: extensible framework
	* High performance
	
Hive architecture

	Hive provides variety of tools:
	
	* Command-line interface
	* Web interface
	* Aplication programming interface (API) like JDBC and ODBC
	
Hive architecture: Internal Components

	* Metastore: Stores system catalog in relational database (RDBMS), with metadata for tables, columns, partitions, etc
	* Driver: Controls lifecycle of a HiveQL statement as it moves through Hive
	* Query Compiler: Parses Hive query and compiles HiveQL into MapReduce task and generates an execution plan with Metastore data
	* Optimizer: Handles optimization tasks on chain of transformations, to reduce execution time
	* Execution Engine: Performs tasks created by compiler and interacts with underlying Hadoop instance
	* Hive Thrift Server: Optional service for using client API to remotely execute HiveQL statements; can be used with various languages (PHP, Perl, Python, etc)
	
Hive Architecture: Workflow

	1. Compiler invoked by driver when HiveQL query received
	2. Compiler translates statement into plan of MapReduce jobs
	3. Driver submits MapReduce jobs to Hadoop execution engine in topological order
	
Hadoop with Hive vs RDBMS

	Hadoop is not an alternative to traditional RDBMS
	Can coexist in one system
	Programmers tend to prefer procedural programmatic approaches like Hadoop to access data
	Non-programmers prefer declarative manipulation languages
	Hadoop with Hive combines both approaches
	
	Comparison:
	
	Traditional RDBMS do not scale with size of data
	Handle high and low latency SQL queries that need to analyze many terabytes of data
	Hadoop can handle petabytes of data
	Hadoop not appropriate for queries requiring fast response times
	
	Key features that are differentiated
	
	Hive can handle petabytes of data and unstructured data; RDBMS only takes structured data
	Hive supports distributed architecture and can run on commodity hardware
	Hive is cost-efficient, but not good for processes with many write features
	RDBMS has high cost to scale
	RDBMS: Traditional features such as transaction management and ACID principles for data reliability