**Representing Data in Pig**

Feeding the Pig - Loading Data

	LOAD statement loads data
	Loads data from storage into Relation
	Pig stores data on HDFS in tab-delimited file
	
	Example code:
	
	result = LOAD 'filename' USING
		fn() AS (field1,field2,...)
		
Example of a LOAD command

	Queries = LOAD 'query_log.txt' USING myLoad() AS (userId,queryString,timestamp)
	
	* Relation = Queries
	* Fields = userId,queryString,timestamp
	* myLoad() = User-provided function that reads in data; Pig supports user-provided Java code
	* PigStorage() = default loader, only works with character-delimited tuple files
	
	Data = LOAD 'query_log.txt' USING PigStorage('\t') AS  (userId,queryString,timestamp);
	
BinStorage()

	Loads data in machine readable format
	Used internally to store temporary data

TextLoader()

	Loads line by ine
	Works with unstructured data
	Resulting tuple contains single field with one line of input text
	Supports compression
	Cannot be used to store data
	
JsonLoader()

	Loads data in standard JSON format
	
Defining the Data - Pig Schema

	Pig can use schema, if one available, if not it will still process the data, using the best guess
	Easiest way to tell Pig which schema is to explicitly tell using AS clause in load
		Grunt > A = LOAD 'input.txt' AS (col1,col2,col3);
	Possible to specify schema without specifying data type (assumed to be bytearray)
	In Hadoop mode and pass directory name to LOAD all files are loaded
	In local mode and pass directory name to LOAD an exception is thrown
	
Output Data from Pig

	DUMP - see output data; useful in debugging process
	STORE - store output data to file system; used for production and batch mode processing. Uses storage functions to store data in desired formats
	CAT - displays content of file on the screen
	
Other Key File Formats and Storage Utilities

	XMLLoader: Loads XML file, implements LoadFunc interface
	RCFile: Data placement structure that determines how to store relational tables on computer clusters
	MultiStorage UDF: Split output data into directories and files dynamically based on user specified key fields

	
