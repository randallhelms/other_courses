**MapReduce Programming**

*JavaAPI for MapReduce*

	Written in Java
	Primary classes of MapReduceAPI are:
		MapReduceBase class
		Partitioner class
		InputFormat and OutputFormat class
		
*Mapper interface and implementation*

	Responsible for data processing in map phase; maps input key-value pairs to intermediate key-value pairs
	Uses map() method to transform input pairs to intermediate pairs
	Implementation must define subclass
	Four generic parameters for input/output key-value pairs
	OutputCollector writes intermediate data
	
*Reducer interface*

	Responsible for data aggregation
	Not sorted
	Optionally can set reduce tasks to zero
	Receives output from mappers and processes them
	Four generic parameters for input/output key-value pairs
	OutputCollector writes final output result
	
*Writing driver for MapReduce*

	Responsible for triggering MapReduce job
	Defines mapper and reducer
	Specifies path of input and output files
	Configures other settings, i.e. waitForCompletion()
	
*Executing the Job and its Output*

Job Execution
	
	Run using Jar: Using Java, i.e. run a normal Jar command
	Run using Streaming API: Use for non-Java languages
	
Output

	Written to HDFS by MyReduce, usually by Reducer
	_SUCCESS is empty file to indicate successful run

*Joins in MapReduce*

	Joining data by key can be helpful
	Example: 2 sets of weather data (1 stations, 1 temperatures)
	Use 1 of 3 joins to do the work:
	Map Side Joins
	Reduce Side Joins (more common)
	Distributed Cache Joins
